{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\rnjsx\\anaconda3\\lib\\site-packages (1.19.2)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.20.1-cp38-cp38-win_amd64.whl (13.7 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\rnjsx\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.1 requires numpy~=1.19.2, but you have numpy 1.20.1 which is incompatible.\n",
      "tensorflow-cpu 2.4.1 requires numpy~=1.19.2, but you have numpy 1.20.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U --user numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py): started\n",
      "  Building wheel for wget (setup.py): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9686 sha256=f0e1a1032ff52a6e43eebd22848e79b28acfc2226b371bf92f04434631b109de\n",
      "  Stored in directory: c:\\users\\rnjsx\\appdata\\local\\pip\\cache\\wheels\\bd\\a8\\c3\\3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12607,
     "status": "ok",
     "timestamp": 1594010753269,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "B9WLyWEWgdDR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import wget\n",
    "\n",
    "MAX_LEN = 384\n",
    "EPOCHS = 3\n",
    "VERBOSE = 2\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1594010762115,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "68HVB3dYgi0w"
   },
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = './data_out/KOR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1594010763471,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "zvoswBdyglTQ"
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, string, string_1, string_2):\n",
    "    # loss \n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history[string_1])\n",
    "    plt.plot(history.history[string_2])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, string_1, string_2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)\n",
    "np.random.seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 65,
     "referenced_widgets": [
      "bc7f3c579a324f77811bdd6ad6dd7dc0",
      "e31de13423d743e68d6c451d23c93cdf",
      "f8f80478dfca4894ac1ff8c2a082f734",
      "3be3c9704e934fb5a3d5847749d398ce",
      "2c0ecef646d44a0580cacefa5c3fd9f2",
      "1fde406732df4b5b90b7701dc7e4981e",
      "f58154a65f974e04bcf8af24b2884fdd",
      "a7d4d0c48cda4abdb106a6bcfb24359e"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1594010812799,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "HDI_cm3sgm6N",
    "outputId": "33078a97-0007-428b-9439-b67bd53cd994"
   },
   "outputs": [],
   "source": [
    "# Save the slow pretrained tokenizer\n",
    "slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", lowercase=False)\n",
    "save_path = \"bert-base-multilingual-cased/\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "slow_tokenizer.save_pretrained(save_path)\n",
    "\n",
    "# Load the fast tokenizer from saved file\n",
    "tokenizer = BertWordPieceTokenizer(\"bert-base-multilingual-cased/vocab.txt\", lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1750,
     "status": "ok",
     "timestamp": 1594010820826,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "an5cGi-GgpG4",
    "outputId": "c7753a24-f338-4a6d-8701-f78753f9b718"
   },
   "outputs": [],
   "source": [
    "train_data_url = \"https://korquad.github.io/dataset/KorQuAD_v1.0_train.json\"\n",
    "train_path = keras.utils.get_file(\"train.json\", train_data_url)\n",
    "eval_data_url = \"https://korquad.github.io/dataset/KorQuAD_v1.0_dev.json\"\n",
    "eval_path = keras.utils.get_file(\"eval.json\", eval_data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% [                                                                                  ]   0 / 625\r",
      "100% [..................................................................................] 625 / 625"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./bert-base-multilingual-cased//bert-base-multilingual-cased-config (1).json'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download('https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json', out='./bert-base-multilingual-cased/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] 파일이 이미 있으므로 만들 수 없습니다: './bert-base-multilingual-cased/bert-base-multilingual-cased-config.json' -> './bert-base-multilingual-cased/config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c9faf48551c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./bert-base-multilingual-cased/bert-base-multilingual-cased-config.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./bert-base-multilingual-cased/config.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] 파일이 이미 있으므로 만들 수 없습니다: './bert-base-multilingual-cased/bert-base-multilingual-cased-config.json' -> './bert-base-multilingual-cased/config.json'"
     ]
    }
   ],
   "source": [
    "os.rename('./bert-base-multilingual-cased/bert-base-multilingual-cased-config.json', './bert-base-multilingual-cased/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [....................................................................] 1083389348 / 1083389348"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./bert-base-multilingual-cased//bert-base-multilingual-cased-tf_model (1).h5'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download('https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-tf_model.h5', out='./bert-base-multilingual-cased/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] 파일이 이미 있으므로 만들 수 없습니다: './bert-base-multilingual-cased/bert-base-multilingual-cased-tf_model.h5' -> './bert-base-multilingual-cased/tf_model.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e0aac52c1f77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./bert-base-multilingual-cased/bert-base-multilingual-cased-tf_model.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./bert-base-multilingual-cased/tf_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] 파일이 이미 있으므로 만들 수 없습니다: './bert-base-multilingual-cased/bert-base-multilingual-cased-tf_model.h5' -> './bert-base-multilingual-cased/tf_model.h5'"
     ]
    }
   ],
   "source": [
    "os.rename('./bert-base-multilingual-cased/bert-base-multilingual-cased-tf_model.h5', './bert-base-multilingual-cased/tf_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 99893,
     "status": "ok",
     "timestamp": 1594011009085,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "PkuK7N_ngrMd",
    "outputId": "48275df3-52de-4623-dfc3-db6be9a54dfa"
   },
   "outputs": [],
   "source": [
    "class SquadExample:\n",
    "    def __init__(self, question, context, start_char_idx, answer_text):\n",
    "        self.question = question\n",
    "        self.context = context\n",
    "        self.start_char_idx = start_char_idx\n",
    "        self.answer_text = answer_text\n",
    "        self.skip = False\n",
    "\n",
    "    def preprocess(self):\n",
    "        context = self.context\n",
    "        question = self.question\n",
    "        answer_text = self.answer_text\n",
    "        start_char_idx = self.start_char_idx\n",
    "\n",
    "        # Clean context, answer and question\n",
    "        context = \" \".join(str(context).split())\n",
    "        question = \" \".join(str(question).split())\n",
    "        answer = \" \".join(str(answer_text).split())\n",
    "\n",
    "        # Find end character index of answer in context\n",
    "        end_char_idx = start_char_idx + len(answer)\n",
    "        if end_char_idx >= len(context):\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "        # Mark the character indexes in context that are in answer\n",
    "        is_char_in_ans = [0] * len(context)\n",
    "        for idx in range(start_char_idx, end_char_idx):\n",
    "            is_char_in_ans[idx] = 1\n",
    "\n",
    "        # Tokenize context\n",
    "        tokenized_context = tokenizer.encode(context)\n",
    "\n",
    "        # Find tokens that were created from answer characters\n",
    "        ans_token_idx = []\n",
    "        for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
    "            if sum(is_char_in_ans[start:end]) > 0:\n",
    "                ans_token_idx.append(idx)\n",
    "\n",
    "        if len(ans_token_idx) == 0:\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "        # Find start and end token index for tokens from answer\n",
    "        start_token_idx = ans_token_idx[0]\n",
    "        end_token_idx = ans_token_idx[-1]\n",
    "\n",
    "        # Tokenize question\n",
    "        tokenized_question = tokenizer.encode(question)\n",
    "\n",
    "        # Create inputs\n",
    "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
    "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(\n",
    "            tokenized_question.ids[1:]\n",
    "        )\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Pad and create attention masks.\n",
    "        # Skip if truncation is needed\n",
    "        padding_length = MAX_LEN - len(input_ids)\n",
    "        if padding_length > 0:  # pad\n",
    "            input_ids = input_ids + ([0] * padding_length)\n",
    "            attention_mask = attention_mask + ([0] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        elif padding_length < 0:  # skip\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "        self.input_ids = input_ids\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.start_token_idx = start_token_idx\n",
    "        self.end_token_idx = end_token_idx\n",
    "        self.context_token_to_char = tokenized_context.offsets\n",
    "\n",
    "\n",
    "def create_squad_examples(raw_data):\n",
    "    squad_examples = []\n",
    "    for item in raw_data[\"data\"]:\n",
    "        for para in item[\"paragraphs\"]:\n",
    "            context = para[\"context\"]\n",
    "            for qa in para[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                answer_text = qa[\"answers\"][0][\"text\"]\n",
    "                start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
    "                squad_eg = SquadExample(\n",
    "                    question, context, start_char_idx, answer_text\n",
    "                )\n",
    "                squad_eg.preprocess()\n",
    "                squad_examples.append(squad_eg)\n",
    "    return squad_examples\n",
    "\n",
    "\n",
    "def create_inputs_targets(squad_examples):\n",
    "    dataset_dict = {\n",
    "        \"input_ids\": [],\n",
    "        \"token_type_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"start_token_idx\": [],\n",
    "        \"end_token_idx\": [],\n",
    "    }\n",
    "    for item in squad_examples:\n",
    "        if item.skip == False:\n",
    "            for key in dataset_dict:\n",
    "                dataset_dict[key].append(getattr(item, key))\n",
    "    for key in dataset_dict:\n",
    "        dataset_dict[key] = np.array(dataset_dict[key])\n",
    "\n",
    "    x = [\n",
    "        dataset_dict[\"input_ids\"],\n",
    "        dataset_dict[\"token_type_ids\"],\n",
    "        dataset_dict[\"attention_mask\"],\n",
    "    ]\n",
    "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60407 training points created.\n",
      "5774 evaluation points created.\n"
     ]
    }
   ],
   "source": [
    "with open(train_path) as f:\n",
    "    raw_train_data = json.load(f)\n",
    "\n",
    "with open(eval_path) as f:\n",
    "    raw_eval_data = json.load(f)\n",
    "\n",
    "\n",
    "train_squad_examples = create_squad_examples(raw_train_data)\n",
    "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
    "print(f\"{len(train_squad_examples)} training points created.\")\n",
    "\n",
    "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
    "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
    "print(f\"{len(eval_squad_examples)} evaluation points created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 690,
     "status": "ok",
     "timestamp": 1594011009787,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "mIjk3_XeguBj"
   },
   "outputs": [],
   "source": [
    "class TFBERTQuestionAnswering(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBERTQuestionAnswering, self).__init__()\n",
    "        \n",
    "        self.encoder = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.start_logit = tf.keras.layers.Dense(num_class, name=\"start_logit\", use_bias=False)\n",
    "        self.end_logit = tf.keras.layers.Dense(num_class, name=\"end_logit\", use_bias=False)\n",
    "        self.flatten = tf.keras.layers.Flatten() \n",
    "        self.softmax = tf.keras.layers.Activation(tf.keras.activations.softmax)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_ids, token_type_ids, attention_mask = inputs\n",
    "        embedding = self.encoder(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)[0]\n",
    "        start_logits = self.start_logit(embedding)\n",
    "        start_logits = self.flatten(start_logits)\n",
    "        \n",
    "        end_logits = self.end_logit(embedding)\n",
    "        end_logits = self.flatten(end_logits)\n",
    "        \n",
    "        start_probs = self.softmax(start_logits)\n",
    "        end_probs = self.softmax(end_logits)\n",
    "    \n",
    "        return start_probs, end_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11135,
     "status": "ok",
     "timestamp": 1594011020239,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "k4t_2T7vgwOu",
    "outputId": "fd7dcb5d-bf36-496c-b53d-53e89962360a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ./bert-base-multilingual-cased/ were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at ./bert-base-multilingual-cased/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "korquad_model = TFBERTQuestionAnswering(model_name='./bert-base-multilingual-cased/',dir_path='bert_ckpt', num_class=1)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1594011103474,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "YZtVFA3PgyL0"
   },
   "outputs": [],
   "source": [
    "def normalized_answer(s):    \n",
    "    def remove_(text):\n",
    "        ''' 불필요한 기호 제거 '''\n",
    "        text = re.sub(\"'\", \" \", text)\n",
    "        text = re.sub('\"', \" \", text)\n",
    "        text = re.sub('《', \" \", text)\n",
    "        text = re.sub('》', \" \", text)\n",
    "        text = re.sub('<', \" \", text)\n",
    "        text = re.sub('>', \" \", text) \n",
    "        text = re.sub('〈', \" \", text)\n",
    "        text = re.sub('〉', \" \", text)   \n",
    "        text = re.sub(\"\\(\", \" \", text)\n",
    "        text = re.sub(\"\\)\", \" \", text)\n",
    "        text = re.sub(\"‘\", \" \", text)\n",
    "        text = re.sub(\"’\", \" \", text)      \n",
    "        return text\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_punc(lower(remove_(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1594011104061,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "rVTh1qKng1p8"
   },
   "outputs": [],
   "source": [
    "class ExactMatch(keras.callbacks.Callback):\n",
    "    def __init__(self, x_eval, y_eval):\n",
    "        self.x_eval = x_eval\n",
    "        self.y_eval = y_eval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
    "        count = 0\n",
    "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
    "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
    "            squad_eg = eval_examples_no_skip[idx]\n",
    "            offsets = squad_eg.context_token_to_char\n",
    "            start = np.argmax(start)\n",
    "            end = np.argmax(end)\n",
    "            if start >= len(offsets):\n",
    "                continue\n",
    "            pred_char_start = offsets[start][0]\n",
    "            if end < len(offsets):\n",
    "                pred_char_end = offsets[end][1]\n",
    "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
    "            else:\n",
    "                pred_ans = squad_eg.context[pred_char_start:]\n",
    "\n",
    "            normalized_pred_ans = normalized_answer(pred_ans)\n",
    "            normalized_true_ans = normalized_answer(squad_eg.answer_text)\n",
    "            if normalized_pred_ans in normalized_true_ans:\n",
    "                count += 1\n",
    "        acc = count / len(self.y_eval[0])\n",
    "        print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 399,
     "status": "ok",
     "timestamp": 1594011104303,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "sTgvtk0og4Ow"
   },
   "outputs": [],
   "source": [
    "exact_match_callback = ExactMatch(x_eval, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1594011105561,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "7EuBYS58g6QZ"
   },
   "outputs": [],
   "source": [
    "korquad_model.compile(optimizer=optimizer, loss=[loss, loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1594011106252,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "ZehxFPSrg8Q2",
    "outputId": "6a33f8a1-84d0-48c4-ac1e-5843daf1f2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_out/KOR\\tf2_bert_korquad -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tf2_bert_korquad\"\n",
    "\n",
    "checkpoint_path = os.path.join(DATA_OUT_PATH, model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18126376,
     "status": "ok",
     "timestamp": 1594029233934,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "2ljuajCLmyws",
    "outputId": "e89526e8-e795-48df-eead-1a00b28005bf"
   },
   "outputs": [],
   "source": [
    "history = korquad_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,  # For demonstration, 3 epochs are recommended\n",
    "    verbose=VERBOSE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[exact_match_callback, cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QxaigHy2m4JB"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss', 'output_1_loss', 'output_2_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "korquad_model.save_weights('weights_KorQuAD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "korquad_model.load_weights('data_out/KOR/tf2_bert_korquad/weights_KorQuAD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListWrapper([<tensorflow.python.keras.losses.SparseCategoricalCrossentropy object at 0x0000021032105A60>, <tensorflow.python.keras.losses.SparseCategoricalCrossentropy object at 0x0000021032105A60>])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korquad_model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-846b5ad6c464>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_graphs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkorquad_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'output_1_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'output_2_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-41e5280c4176>\u001b[0m in \u001b[0;36mplot_graphs\u001b[1;34m(history, string, string_1, string_2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_graphs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstring_1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstring_2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "plot_graphs(korquad_model.history,'loss', 'output_1_loss', 'output_2_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 predict 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 지문 찾아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의 ( 폭력행위등처벌에관한법률위반 ) 으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일 ~ 20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다. 1989년 6월 30일 평양축전에 대표로 파견 된 인물은?\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(x_eval[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(x_eval[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_context= tokenizer.encode(\"1989년 6월 30일 평양축전에 대표로 파견 된 인물은?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 5), (6, 8), (9, 12), (13, 14), (14, 15), (15, 16), (16, 18), (19, 20), (20, 21), (21, 22), (23, 24), (24, 25), (26, 27), (28, 29), (29, 30), (30, 31), (31, 32), (0, 0)]\n"
     ]
    }
   ],
   "source": [
    "context_token_to_char = tokenized_context.offsets\n",
    "print(context_token_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1989년'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([x_eval[0][1][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1989년\n",
      "2월\n",
      "15일\n",
      "여\n",
      "##의\n",
      "##도\n",
      "농\n",
      "##민\n",
      "폭\n",
      "##력\n",
      "시\n",
      "##위를\n",
      "주\n",
      "##도\n",
      "##한\n",
      "혐\n",
      "##의\n",
      "(\n",
      "폭\n",
      "##력\n",
      "##행\n",
      "##위\n",
      "##등\n",
      "##처\n",
      "##벌\n",
      "##에\n",
      "##관\n",
      "##한\n",
      "##법\n",
      "##률\n",
      "##위\n",
      "##반\n",
      ")\n",
      "으로\n",
      "지\n",
      "##명\n",
      "##수\n",
      "##배\n",
      "##되었다\n",
      ".\n",
      "1989년\n",
      "3월\n",
      "12일\n",
      "서울\n",
      "##지\n",
      "##방\n",
      "##검\n",
      "##찰\n",
      "##청\n",
      "공\n",
      "##안\n",
      "##부는\n",
      "임\n",
      "##종\n",
      "##석\n",
      "##의\n",
      "사\n",
      "##전\n",
      "##구\n",
      "##속\n",
      "##영\n",
      "##장을\n",
      "발\n",
      "##부\n",
      "##받\n",
      "##았다\n",
      ".\n",
      "같은\n",
      "해\n",
      "6월\n",
      "30일\n",
      "평\n",
      "##양\n",
      "##축\n",
      "##전에\n",
      "임\n",
      "##수\n",
      "##경\n",
      "##을\n",
      "대\n",
      "##표\n",
      "##로\n",
      "파\n",
      "##견\n",
      "##하여\n",
      "국가\n",
      "##보\n",
      "##안\n",
      "##법\n",
      "##위\n",
      "##반\n",
      "혐\n",
      "##의\n",
      "##가\n",
      "추\n",
      "##가\n",
      "##되었다\n",
      ".\n",
      "경\n",
      "##찰\n",
      "##은\n",
      "12월\n",
      "18일\n",
      "~\n",
      "20일\n",
      "사\n",
      "##이\n",
      "서울\n",
      "경\n",
      "##희\n",
      "##대학교\n",
      "##에서\n",
      "임\n",
      "##종\n",
      "##석\n",
      "##이\n",
      "성\n",
      "##명\n",
      "발\n",
      "##표\n",
      "##를\n",
      "추\n",
      "##진\n",
      "##하고\n",
      "있다는\n",
      "첩\n",
      "##보를\n",
      "입\n",
      "##수\n",
      "##했고\n",
      ",\n",
      "12월\n",
      "18일\n",
      "오\n",
      "##전\n",
      "7\n",
      "##시\n",
      "40\n",
      "##분\n",
      "경\n",
      "가\n",
      "##스\n",
      "##총\n",
      "##과\n",
      "전\n",
      "##자\n",
      "##봉\n",
      "##으로\n",
      "무\n",
      "##장\n",
      "##한\n",
      "특\n",
      "##공\n",
      "##조\n",
      "및\n",
      "대\n",
      "##공\n",
      "##과\n",
      "직\n",
      "##원\n",
      "12\n",
      "##명\n",
      "등\n",
      "22\n",
      "##명의\n",
      "사\n",
      "##복\n",
      "경\n",
      "##찰\n",
      "##을\n",
      "승\n",
      "##용\n",
      "##차\n",
      "8\n",
      "##대에\n",
      "나\n",
      "##누\n",
      "##어\n",
      "경\n",
      "##희\n",
      "##대학교\n",
      "##에\n",
      "투\n",
      "##입\n",
      "##했다\n",
      ".\n",
      "1989년\n",
      "12월\n",
      "18일\n",
      "오\n",
      "##전\n",
      "8\n",
      "##시\n",
      "15\n",
      "##분\n",
      "경\n",
      "서울\n",
      "##청\n",
      "##량\n",
      "##리\n",
      "##경\n",
      "##찰\n",
      "##서는\n",
      "호\n",
      "##위\n",
      "학\n",
      "##생\n",
      "5\n",
      "##명\n",
      "##과\n",
      "함께\n",
      "경\n",
      "##희\n",
      "##대학교\n",
      "학\n",
      "##생\n",
      "##회\n",
      "##관\n",
      "건\n",
      "##물\n",
      "계\n",
      "##단\n",
      "##을\n",
      "내\n",
      "##려\n",
      "##오는\n",
      "임\n",
      "##종\n",
      "##석\n",
      "##을\n",
      "발\n",
      "##견\n",
      ",\n",
      "검\n",
      "##거\n",
      "##해\n",
      "구\n",
      "##속\n",
      "##을\n",
      "집\n",
      "##행\n",
      "##했다\n",
      ".\n",
      "임\n",
      "##종\n",
      "##석\n",
      "##은\n",
      "청\n",
      "##량\n",
      "##리\n",
      "##경\n",
      "##찰\n",
      "##서\n",
      "##에서\n",
      "약\n",
      "1\n",
      "##시간\n",
      "동안\n",
      "조\n",
      "##사를\n",
      "받은\n",
      "뒤\n",
      "오\n",
      "##전\n",
      "9\n",
      "##시\n",
      "50\n",
      "##분\n",
      "경\n",
      "서울\n",
      "장\n",
      "##안\n",
      "##동\n",
      "##의\n",
      "서울\n",
      "##지\n",
      "##방\n",
      "##경\n",
      "##찰\n",
      "##청\n",
      "공\n",
      "##안\n",
      "##분\n",
      "##실\n",
      "##로\n",
      "인\n",
      "##계\n",
      "##되었다\n",
      ".\n",
      "\n",
      "1989년\n",
      "6월\n",
      "30일\n",
      "평\n",
      "##양\n",
      "##축\n",
      "##전에\n",
      "대\n",
      "##표\n",
      "##로\n",
      "파\n",
      "##견\n",
      "된\n",
      "인\n",
      "##물\n",
      "##은\n",
      "?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in x_eval[0][1]:\n",
    "    print(tokenizer.decode([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   101  76485  17520  37912   9565  10459  12092   9027  36553   9929\n",
      "  28143   9485  31166   9689  12092  11102   9980  10459    113   9929\n",
      "  28143  25549  19855 101322  60469  68773  10530  20595  11102  33768\n",
      "  88350  19855  30134    114  29805   9706  16758  15891  76036  13628\n",
      "    119  76485  15361  46026  48253  12508  42337 118625  99118  40311\n",
      "   8896  34951  58904   9644  22200  40958  10459   9405  16617  17196\n",
      "  43962  30858  35963   9323  14646 118965  27303    119  18589   9960\n",
      "  17253  40636   9926  37114  70122  68767   9644  15891  31720  10622\n",
      "   9069  37824  11261   9901 118634  13374  93222  30005  34951  33768\n",
      "  19855  30134   9980  10459  11287   9765  11287  13628    119   8885\n",
      "  99118  10892  16367  45972    198  41518   9405  10739  48253   8885\n",
      "  49515  30461  11489   9644  22200  40958  10739   9434  16758   9323\n",
      "  37824  11513   9765  18623  12453  77324   9749  91693   9645  15891\n",
      "  38181    117  16367  45972   9580  16617    128  14040  10533  37712\n",
      "   8885   8843  12605 119270  11882   9665  13764 118989  11467   9294\n",
      "  13890  11102   9891  28000  20626   9316   9069  28000  11882   9707\n",
      "  14279  10186  16758   9121  10306  45441   9405  70915   8885  99118\n",
      "  10622   9484  24974  23466    129  81980   8982 118751  12965   8885\n",
      "  49515  30461  10530   9881  58303  12490    119  76485  16367  45972\n",
      "   9580  16617    129  14040  10208  37712   8885  48253  40311  44321\n",
      "  12692  31720  99118  37321   9985  19855   9953  24017    126  16758\n",
      "  11882  19653   8885  49515  30461   9953  24017  14863  20595   8865\n",
      "  29364   8887  24989  10622   8996  26737  82823   9644  22200  40958\n",
      "  10622   9323 118634    117   8868  41521  14523   8908  43962  10622\n",
      "   9711  25549  12490    119   9644  22200  40958  10892   9751  44321\n",
      "  12692  31720  99118  12424  11489   9539    122 100699  41886   9678\n",
      "  32159  74141   9109   9580  16617    130  14040  10462  37712   8885\n",
      "  48253   9657  34951  18778  10459  48253  12508  42337  31720  99118\n",
      "  40311   8896  34951  37712  31503  11261   9640  21611  13628    119\n",
      "    102  76485  17253  40636   9926  37114  70122  68767   9069  37824\n",
      "  11261   9901 118634   9099   9640  29364  10892    136    102      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0]\n"
     ]
    }
   ],
   "source": [
    "print(x_eval[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_context.ids= [101, 9657, 30858, 31503, 10892, 9323, 16758, 11287, 92413, 10459, 10005, 118901, 11102, 9659, 16323, 11513, 9854, 22200, 10739, 9640, 16605, 13374, 9323, 119335, 12609, 119, 9435, 22200, 10892, 9489, 24974, 37224, 57713, 12424, 9657, 30858, 31503, 10459, 9664, 36456, 9694, 48549, 17594, 9420, 66540, 13374, 9365, 40991, 10459, 9109, 11513, 64749, 9694, 24974, 12609, 119, 9435, 22200, 10892, 9657, 30858, 83380, 77158, 10954, 113, 9435, 22200, 125, 10954, 114, 9627, 12945, 119171, 113, 3476, 3169, 8270, 114, 117, 9764, 38631, 17196, 113, 3548, 3198, 7079, 114, 105464, 19653, 45397, 10530, 9356, 31605, 12965, 9746, 25934, 12310, 46874, 9283, 37114, 10622, 9330, 69592, 28188, 71689, 23622, 119, 8920, 20479, 10003, 9657, 30858, 31503, 8982, 10739, 9539, 11069, 24982, 9137, 12030, 92091, 10954, 113, 9435, 22200, 126, 10954, 114, 9559, 9746, 25934, 12310, 29669, 104865, 11102, 8896, 10622, 9640, 16605, 118965, 16985, 9279, 38631, 49953, 25805, 82642, 25258, 9637, 118743, 10622, 69642, 9684, 11166, 52951, 9414, 10459, 14279, 113, 3465, 7080, 8222, 114, 9353, 119215, 10530, 9644, 16758, 13628, 119, 164, 124, 166, 83589, 10954, 113, 9435, 22200, 11211, 114, 17162, 117, 9644, 40032, 10892, 76203, 9670, 11166, 52951, 9966, 12945, 33077, 11467, 9484, 18623, 14040, 119305, 11664, 8861, 34907, 12508, 12310, 113, 4449, 5286, 2120, 2970, 114, 9233, 9248, 27023, 59894, 9281, 12490, 119, 8924, 37388, 12424, 8982, 37093, 27487, 9750, 9299, 14040, 21611, 34776, 119, 102]\n",
      "tokenized_question.ids= [101, 9746, 25934, 12310, 29669, 104865, 11102, 8896, 10622, 9640, 16605, 118965, 16985, 9279, 38631, 13441, 9018, 60884, 136, 102]\n",
      "padding_length= 138\n",
      "input_ids= [101, 9657, 30858, 31503, 10892, 9323, 16758, 11287, 92413, 10459, 10005, 118901, 11102, 9659, 16323, 11513, 9854, 22200, 10739, 9640, 16605, 13374, 9323, 119335, 12609, 119, 9435, 22200, 10892, 9489, 24974, 37224, 57713, 12424, 9657, 30858, 31503, 10459, 9664, 36456, 9694, 48549, 17594, 9420, 66540, 13374, 9365, 40991, 10459, 9109, 11513, 64749, 9694, 24974, 12609, 119, 9435, 22200, 10892, 9657, 30858, 83380, 77158, 10954, 113, 9435, 22200, 125, 10954, 114, 9627, 12945, 119171, 113, 3476, 3169, 8270, 114, 117, 9764, 38631, 17196, 113, 3548, 3198, 7079, 114, 105464, 19653, 45397, 10530, 9356, 31605, 12965, 9746, 25934, 12310, 46874, 9283, 37114, 10622, 9330, 69592, 28188, 71689, 23622, 119, 8920, 20479, 10003, 9657, 30858, 31503, 8982, 10739, 9539, 11069, 24982, 9137, 12030, 92091, 10954, 113, 9435, 22200, 126, 10954, 114, 9559, 9746, 25934, 12310, 29669, 104865, 11102, 8896, 10622, 9640, 16605, 118965, 16985, 9279, 38631, 49953, 25805, 82642, 25258, 9637, 118743, 10622, 69642, 9684, 11166, 52951, 9414, 10459, 14279, 113, 3465, 7080, 8222, 114, 9353, 119215, 10530, 9644, 16758, 13628, 119, 164, 124, 166, 83589, 10954, 113, 9435, 22200, 11211, 114, 17162, 117, 9644, 40032, 10892, 76203, 9670, 11166, 52951, 9966, 12945, 33077, 11467, 9484, 18623, 14040, 119305, 11664, 8861, 34907, 12508, 12310, 113, 4449, 5286, 2120, 2970, 114, 9233, 9248, 27023, 59894, 9281, 12490, 119, 8924, 37388, 12424, 8982, 37093, 27487, 9750, 9299, 14040, 21611, 34776, 119, 102, 9746, 25934, 12310, 29669, 104865, 11102, 8896, 10622, 9640, 16605, 118965, 16985, 9279, 38631, 13441, 9018, 60884, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids= [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_mask= [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[array([[   101,   9657,  30858,  31503,  10892,   9323,  16758,  11287,\n",
      "         92413,  10459,  10005, 118901,  11102,   9659,  16323,  11513,\n",
      "          9854,  22200,  10739,   9640,  16605,  13374,   9323, 119335,\n",
      "         12609,    119,   9435,  22200,  10892,   9489,  24974,  37224,\n",
      "         57713,  12424,   9657,  30858,  31503,  10459,   9664,  36456,\n",
      "          9694,  48549,  17594,   9420,  66540,  13374,   9365,  40991,\n",
      "         10459,   9109,  11513,  64749,   9694,  24974,  12609,    119,\n",
      "          9435,  22200,  10892,   9657,  30858,  83380,  77158,  10954,\n",
      "           113,   9435,  22200,    125,  10954,    114,   9627,  12945,\n",
      "        119171,    113,   3476,   3169,   8270,    114,    117,   9764,\n",
      "         38631,  17196,    113,   3548,   3198,   7079,    114, 105464,\n",
      "         19653,  45397,  10530,   9356,  31605,  12965,   9746,  25934,\n",
      "         12310,  46874,   9283,  37114,  10622,   9330,  69592,  28188,\n",
      "         71689,  23622,    119,   8920,  20479,  10003,   9657,  30858,\n",
      "         31503,   8982,  10739,   9539,  11069,  24982,   9137,  12030,\n",
      "         92091,  10954,    113,   9435,  22200,    126,  10954,    114,\n",
      "          9559,   9746,  25934,  12310,  29669, 104865,  11102,   8896,\n",
      "         10622,   9640,  16605, 118965,  16985,   9279,  38631,  49953,\n",
      "         25805,  82642,  25258,   9637, 118743,  10622,  69642,   9684,\n",
      "         11166,  52951,   9414,  10459,  14279,    113,   3465,   7080,\n",
      "          8222,    114,   9353, 119215,  10530,   9644,  16758,  13628,\n",
      "           119,    164,    124,    166,  83589,  10954,    113,   9435,\n",
      "         22200,  11211,    114,  17162,    117,   9644,  40032,  10892,\n",
      "         76203,   9670,  11166,  52951,   9966,  12945,  33077,  11467,\n",
      "          9484,  18623,  14040, 119305,  11664,   8861,  34907,  12508,\n",
      "         12310,    113,   4449,   5286,   2120,   2970,    114,   9233,\n",
      "          9248,  27023,  59894,   9281,  12490,    119,   8924,  37388,\n",
      "         12424,   8982,  37093,  27487,   9750,   9299,  14040,  21611,\n",
      "         34776,    119,    102,   9746,  25934,  12310,  29669, 104865,\n",
      "         11102,   8896,  10622,   9640,  16605, 118965,  16985,   9279,\n",
      "         38631,  13441,   9018,  60884,    136,    102,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]\n",
      "1423년\n"
     ]
    }
   ],
   "source": [
    "class SquadExample_pred:\n",
    "    def __init__(self, question, context):#, start_char_idx, answer_text):\n",
    "        self.question = question\n",
    "        self.context = context\n",
    "        self.skip = False\n",
    "\n",
    "    def preprocess(self):\n",
    "        context = self.context\n",
    "        question = self.question\n",
    "        #answer_text = self.answer_text\n",
    "        #start_char_idx = self.start_char_idx\n",
    "\n",
    "        # Clean context, answer and question\n",
    "        context = \" \".join(str(context).split())\n",
    "        question = \" \".join(str(question).split())\n",
    "\n",
    "        # Tokenize context\n",
    "        tokenized_context = tokenizer.encode(context)\n",
    "        print(\"tokenized_context.ids=\", tokenized_context.ids)\n",
    "\n",
    "        # Tokenize question\n",
    "        tokenized_question = tokenizer.encode(question)\n",
    "        print(\"tokenized_question.ids=\", tokenized_question.ids)\n",
    "\n",
    "        # Create inputs\n",
    "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
    "        \n",
    "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(\n",
    "            tokenized_question.ids[1:]\n",
    "        )\n",
    "        \n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        \n",
    "\n",
    "        # Pad and create attention masks.\n",
    "        # Skip if truncation is needed\n",
    "        \n",
    "        padding_length = MAX_LEN - len(input_ids)\n",
    "        print(\"padding_length=\",padding_length)\n",
    "        \n",
    "        if padding_length > 0:  # pad\n",
    "            input_ids = input_ids + ([0] * padding_length)\n",
    "            attention_mask = attention_mask + ([0] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        elif padding_length < 0:  # skip\n",
    "            self.skip = True\n",
    "            return\n",
    "        \n",
    "        print(\"input_ids=\", input_ids)\n",
    "        print(\"token_type_ids=\", token_type_ids)\n",
    "        print(\"attention_mask=\", attention_mask)\n",
    "\n",
    "        self.input_ids = input_ids\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.context_token_to_char = tokenized_context.offsets\n",
    "#         print(self.context_token_to_char)\n",
    "        \n",
    "    def get_input_target(self):\n",
    "        dataset_dict = {\n",
    "            \"input_ids\": [],\n",
    "            \"token_type_ids\": [],\n",
    "            \"attention_mask\": [],\n",
    "        }\n",
    "        if self.skip == False:\n",
    "            for key in dataset_dict:\n",
    "                dataset_dict[key].append(getattr(self, key))\n",
    "        for key in dataset_dict:\n",
    "            dataset_dict[key] = np.array(dataset_dict[key])\n",
    "\n",
    "        x = [\n",
    "            dataset_dict[\"input_ids\"],\n",
    "            dataset_dict[\"token_type_ids\"],\n",
    "            dataset_dict[\"attention_mask\"],\n",
    "        ]\n",
    "        print(x)\n",
    "        return x\n",
    "\n",
    "def create_squad_examples_from_arg(question, context):#, start_char_idx, answer_text):\n",
    "    squad_eg = SquadExample_pred(\n",
    "        question, context#, start_char_idx, answer_text\n",
    "    )\n",
    "    squad_eg.preprocess()\n",
    "    return squad_eg\n",
    "\n",
    "\n",
    "def predict_test(model, pred_raw):\n",
    "    x_pred = pred_raw.get_input_target()\n",
    "    pred_start, pred_end = model.predict(x_pred)\n",
    "    \n",
    "    pred_start_offset_index = np.argmax(pred_start)\n",
    "    pred_end_offset_index = np.argmax(pred_end)\n",
    "    pred_start_offset = pred_raw.context_token_to_char[pred_start_offset_index]\n",
    "    pred_end_offset = pred_raw.context_token_to_char[pred_end_offset_index]\n",
    "    answer = pred_context[pred_start_offset[0]:pred_end_offset[1]]\n",
    "    \n",
    "    normalized_pred_ans = normalized_answer(answer)\n",
    "    \n",
    "    return normalized_pred_ans\n",
    "\n",
    "\n",
    "pred_question = \"천문기기를 제작한 공을 인정받아 면천된 년도는?\"\n",
    "pred_context = \"장영실은 발명가로서의 훌륭한 재주를 태종이 인정하여 발탁하였다. 세종은 실용주의자로서 장영실의 적성을 중요하게 생각하여 부왕의 뒤를 이어 중용하였다. 세종은 장영실을 1421년(세종 4년) 윤사웅(尹士雄), 최천구(崔天衢) 등과 함께 중국에 보내어 천문기기의 모양을 배워오도록 했다. 귀국 후 장영실 나이 약 34세 때인 1423년(세종 5년)에 천문기기를 제작한 공을 인정받아 면천되었고 다시 대신들의 의논을 거쳐 종5품 상의원(尙衣院) 별좌에 임명되었다.[3] 1424년(세종6) 5월, 임금은 그를 정5품 행사직으로 승진시켰고 갱점지기(更点之器)를 만들라고 명했다. 그래서 나온 것이 첫 물시계였다.\"\n",
    "\n",
    "pred_data = create_squad_examples_from_arg(pred_question, pred_context)\n",
    "pred_answer = predict_test(korquad_model, pred_data)\n",
    "print(pred_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMn6I90a+EqoM9Ks6eBcRWt",
   "collapsed_sections": [],
   "name": "KorQuad_class.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1fde406732df4b5b90b7701dc7e4981e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c0ecef646d44a0580cacefa5c3fd9f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3be3c9704e934fb5a3d5847749d398ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7d4d0c48cda4abdb106a6bcfb24359e",
      "placeholder": "​",
      "style": "IPY_MODEL_f58154a65f974e04bcf8af24b2884fdd",
      "value": " 872k/872k [00:00&lt;00:00, 3.17MB/s]"
     }
    },
    "a7d4d0c48cda4abdb106a6bcfb24359e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc7f3c579a324f77811bdd6ad6dd7dc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f8f80478dfca4894ac1ff8c2a082f734",
       "IPY_MODEL_3be3c9704e934fb5a3d5847749d398ce"
      ],
      "layout": "IPY_MODEL_e31de13423d743e68d6c451d23c93cdf"
     }
    },
    "e31de13423d743e68d6c451d23c93cdf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f58154a65f974e04bcf8af24b2884fdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8f80478dfca4894ac1ff8c2a082f734": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fde406732df4b5b90b7701dc7e4981e",
      "max": 871891,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2c0ecef646d44a0580cacefa5c3fd9f2",
      "value": 871891
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
